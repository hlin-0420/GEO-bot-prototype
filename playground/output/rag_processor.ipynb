{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d054179",
   "metadata": {},
   "source": [
    "# RAG Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcfce3e",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c3b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import networkx as nx\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d33799",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc0d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Parse HTML and extract nodes/edges\n",
    "def extract_graph_from_html(html_path):\n",
    "    with open(html_path, 'r', encoding='utf-8') as f:\n",
    "        soup = BeautifulSoup(f, 'html.parser')\n",
    "        script_content = soup.find_all('script')[-1].string\n",
    "        \n",
    "        nodes_match = re.search(r'nodes\\s*=\\s*new vis\\.DataSet\\((\\[.*?\\])\\);', script_content, re.DOTALL)\n",
    "        edges_match = re.search(r'edges\\s*=\\s*new vis\\.DataSet\\((\\[.*?\\])\\);', script_content, re.DOTALL)\n",
    "\n",
    "        nodes = json.loads(nodes_match.group(1)) if nodes_match else []\n",
    "        edges = json.loads(edges_match.group(1)) if edges_match else []\n",
    "\n",
    "        G = nx.Graph()\n",
    "        for node in nodes:\n",
    "            G.add_node(node['id'], label=node.get('title', 'Type'))\n",
    "\n",
    "        for edge in edges:\n",
    "            G.add_edge(edge['from'], edge['to'])\n",
    "\n",
    "        return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e42fec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_file = \"knowledge_graph_geo_limits.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd4c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = extract_graph_from_html(html_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8809ec05",
   "metadata": {},
   "source": [
    "## Graph to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b62fc17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_text_chunks(G):\n",
    "    text_chunks = []\n",
    "    for u, v in G.edges():\n",
    "        text_chunks.append(f\"{u}: {v}\")\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45fb70da",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = graph_to_text_chunks(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc53999",
   "metadata": {},
   "source": [
    "## Vector Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddeb4044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create vector index for retrieval\n",
    "def build_vector_index(text_chunks):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(text_chunks)\n",
    "\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(np.array(embeddings))\n",
    "\n",
    "    return index, embeddings, text_chunks, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee67831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index, embeddings, chunk_map, model = build_vector_index(text_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c920eec8",
   "metadata": {},
   "source": [
    "## Retrieval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "361d84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_info(query, model, index, text_chunks, top_k=3):\n",
    "    query_emb = model.encode([query])\n",
    "    D, I = index.search(np.array(query_emb), top_k)\n",
    "    return [text_chunks[i] for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d686abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_questions = [\n",
    "    \"Why can't I add 251 curve shades to my log?\",\n",
    "    \"What is the maximum number of data points allowed per curve?\",\n",
    "    \"I want to use the name 'Hydrocarbon bearing zone highlighted' as my curve shade name. Why is it not allowed?\",\n",
    "    \"What is the number of curves I can load in a data file?\",\n",
    "    \"I have already added 20,000 modifiers to my log. Why can't I add more?\",\n",
    "    \"How many log headers can I add to my log?\",\n",
    "    \"How many tadpole definitions am I allowed to create?\",\n",
    "    \"Why can't I add another layout to my log?\"\n",
    "]\n",
    "# Remove word \"maximum\" from \"What is the maximum number of curves I can load in a data file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "008bf36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: Why can't I add 251 curve shades to my log?\n",
      "Top Retrieved Info:\n",
      "- 250: Number of curve shades per plot\n",
      "- 20: Curve shade name length\n",
      "- 50: Number of zones per curve shade\n",
      "\n",
      "Question: What is the maximum number of data points allowed per curve?\n",
      "Top Retrieved Info:\n",
      "- Data points per curve: Unlimited\n",
      "- Number of data files to form one curve: None\n",
      "- Number of curves: 450\n",
      "\n",
      "Question: I want to use the name 'Hydrocarbon bearing zone highlighted' as my curve shade name. Why is it not allowed?\n",
      "Top Retrieved Info:\n",
      "- Curve to lithology name: 50\n",
      "- 20: Curve shade name length\n",
      "- 50: Number of zones per curve shade\n",
      "\n",
      "Question: What is the number of curves I can load in a data file?\n",
      "Top Retrieved Info:\n",
      "- Number of data files to form one curve: None\n",
      "- Data points per curve: Unlimited\n",
      "- Number of curves: 450\n",
      "\n",
      "Question: I have already added 20,000 modifiers to my log. Why can't I add more?\n",
      "Top Retrieved Info:\n",
      "- 20000: Number of modifiers per plot\n",
      "- 450: Number of modifier types\n",
      "- Number of rows in 'operations diary' type table: 4320\n",
      "\n",
      "Question: How many log headers can I add to my log?\n",
      "Top Retrieved Info:\n",
      "- 50: Number of specifications to make a plot header\n",
      "- 100: Number of header & trailers specification files\n",
      "- Number of track text blocks per plot: 6000\n",
      "\n",
      "Question: How many tadpole definitions am I allowed to create?\n",
      "Top Retrieved Info:\n",
      "- 50: Maximum tadpole definition templates\n",
      "- Tadpole definitions: 5\n",
      "- Tadpole definitions name: 16\n",
      "\n",
      "Question: Why can't I add another layout to my log?\n",
      "Top Retrieved Info:\n",
      "- Maximum layouts per ODF: 19\n",
      "- Number of track text blocks per plot: 6000\n",
      "- 29: Size of plot description\n"
     ]
    }
   ],
   "source": [
    "for question in sample_questions:\n",
    "    results = retrieve_info(question, model, index, chunk_map)\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    print(\"Top Retrieved Info:\")\n",
    "    for res in results:\n",
    "        print(f\"- {res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb620b2b",
   "metadata": {},
   "source": [
    "## Model Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58eb009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dc9e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Ollama\n",
    "llm_model = ChatOllama(\n",
    "    model=\"llama3.2:latest\",  # or any other local model you have\n",
    "    temperature=0,\n",
    "    num_predict=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd983e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an expert on GEO limits and constraints.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Answer concisely based on the context.\n",
    "    \"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6fb0b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def generate_ollama_answer(question, retrieved_facts, llm_model, prompt_template):\n",
    "    context = \"\\n\".join(f\"- {fact}\" for fact in retrieved_facts)\n",
    "    \n",
    "    # Define the chain properly\n",
    "    rag_chain = (\n",
    "        {\"context\": RunnablePassthrough(), \"question\": RunnablePassthrough()}\n",
    "        | prompt_template\n",
    "        | llm_model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    # Pass context and question as a dict\n",
    "    answer = rag_chain.invoke({\"context\": context, \"question\": question})\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eda45350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: Why can't I add 251 curve shades to my log?\n",
      "Top Retrieved Info:\n",
      "- 250: Number of curve shades per plot\n",
      "- 20: Curve shade name length\n",
      "- 50: Number of zones per curve shade\n",
      "Answer: The limit of 250 curve shades is due to a technical constraint. This limitation prevents excessive data from being displayed, maintaining readability and usability in the log.\n",
      "\n",
      "Question: What is the maximum number of data points allowed per curve?\n",
      "Top Retrieved Info:\n",
      "- Data points per curve: Unlimited\n",
      "- Number of data files to form one curve: None\n",
      "- Number of curves: 450\n",
      "Answer: The maximum number of data points allowed per curve is Unlimited.\n",
      "\n",
      "Question: I want to use the name 'Hydrocarbon bearing zone highlighted' as my curve shade name. Why is it not allowed?\n",
      "Top Retrieved Info:\n",
      "- Curve to lithology name: 50\n",
      "- 20: Curve shade name length\n",
      "- 50: Number of zones per curve shade\n",
      "Answer: The curve shade name 'Hydrocarbon bearing zone highlighted' exceeds the maximum length of 20 characters, which is a constraint defined in the system.\n",
      "\n",
      "Question: What is the number of curves I can load in a data file?\n",
      "Top Retrieved Info:\n",
      "- Number of data files to form one curve: None\n",
      "- Data points per curve: Unlimited\n",
      "- Number of curves: 450\n",
      "Answer: According to the context, there is no limit specified for the number of curves that can be loaded in a single data file. The only constraint mentioned is that there are 450 curves available in total.\n",
      "\n",
      "Question: I have already added 20,000 modifiers to my log. Why can't I add more?\n",
      "Top Retrieved Info:\n",
      "- 20000: Number of modifiers per plot\n",
      "- 450: Number of modifier types\n",
      "- Number of rows in 'operations diary' type table: 4320\n",
      "Answer: The reason you cannot add more modifiers is because you have reached the maximum allowed number of modifiers per plot, which is 20,000.\n",
      "\n",
      "Question: How many log headers can I add to my log?\n",
      "Top Retrieved Info:\n",
      "- 50: Number of specifications to make a plot header\n",
      "- 100: Number of header & trailers specification files\n",
      "- Number of track text blocks per plot: 6000\n",
      "Answer: Based on the provided context, there is no specific limit mentioned for log headers. The limits mentioned are related to plot specifications (50 for plot headers, 100 for header/trailers files, and 6000 for track text blocks).\n",
      "\n",
      "Question: How many tadpole definitions am I allowed to create?\n",
      "Top Retrieved Info:\n",
      "- 50: Maximum tadpole definition templates\n",
      "- Tadpole definitions: 5\n",
      "- Tadpole definitions name: 16\n",
      "Answer: You are allowed to create up to 5 tadpole definitions.\n",
      "\n",
      "Question: Why can't I add another layout to my log?\n",
      "Top Retrieved Info:\n",
      "- Maximum layouts per ODF: 19\n",
      "- Number of track text blocks per plot: 6000\n",
      "- 29: Size of plot description\n",
      "Answer: The maximum number of layouts per ODF (OpenDocument Format) is 19. You have already reached this limit, which prevents you from adding another layout to your log.\n"
     ]
    }
   ],
   "source": [
    "# Loop over sample questions and get answers\n",
    "for question in sample_questions:\n",
    "    results = retrieve_info(question, model, index, chunk_map)\n",
    "    # print(type(results))\n",
    "    answer = generate_ollama_answer(question, results, llm_model, prompt_template)\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    print(\"Top Retrieved Info:\")\n",
    "    for res in results:\n",
    "        print(f\"- {res}\")\n",
    "    print(\"Answer:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
