{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from haystack.telemetry import tutorial_running\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial_running(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"Data\")\n",
    "EXCEL_FILE = os.path.join(DATA_DIR, \"query_responses.xlsx\")\n",
    "FEEDBACK_FILE = os.path.join(DATA_DIR, \"feedback_dataset.json\")\n",
    "PROMPT_VISUALISATION_FILE = os.path.join(DATA_DIR, \"prompt_visualisation.txt\")\n",
    "PROCESSED_CONTENT_FILE = os.path.join(DATA_DIR, \"processed_content.txt\")\n",
    "UPLOADED_FILE = os.path.join(DATA_DIR, \"uploaded_document.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _list_htm_files():\n",
    "    \"\"\"\n",
    "    Recursively finds all .htm files in the DATA_DIR and its subdirectories.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of full file paths.\n",
    "    \"\"\"\n",
    "    htm_files = []\n",
    "    for root, _, files in os.walk(DATA_DIR):\n",
    "        for file in files:\n",
    "            if file.endswith(\".htm\"):\n",
    "                full_path = os.path.join(root, file)  # Get the absolute path\n",
    "                htm_files.append(full_path)  \n",
    "\n",
    "    return htm_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(soup):\n",
    "    # Extract only meaningful paragraph text\n",
    "    paragraphs = [p.get_text(strip=True) for p in soup.find_all(\"p\") if len(p.get_text(strip=True)) > 20]  # Exclude very short text\n",
    "    clean_text = \"\\n\\n\".join(paragraphs)\n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_table(table_text):\n",
    "    \"\"\"\n",
    "    Reformats the extracted table text into a structured and retrievable format.\n",
    "\n",
    "    Args:\n",
    "        table_text (str): Raw extracted table text.\n",
    "\n",
    "    Returns:\n",
    "        str: Reformatted text suitable for retrieval.\n",
    "    \"\"\"\n",
    "    rows = table_text.split(\"\\n\")\n",
    "    reformatted_lines = []\n",
    "    \n",
    "    for row in rows:\n",
    "        # Match table rows that contain data (ignoring separators like \"+----+\")\n",
    "        match = re.match(r\"\\|\\s*(\\d+)\\s*\\|\\s*(.*?)\\s*\\|\\s*(.*?)\\s*\\|\", row)\n",
    "        if match:\n",
    "            _, key, value = match.groups()\n",
    "            key = key.strip()\n",
    "            value = value.strip()\n",
    "            \n",
    "            # Ensure meaningful values exist before adding\n",
    "            if key and value and value.lower() != \"none\":\n",
    "                reformatted_lines.append(f\"{key}: {value}\")\n",
    "\n",
    "    return \"\\n\".join(reformatted_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table(soup):\n",
    "    tables = soup.find_all(\"table\")\n",
    "    formatted_tables = []\n",
    "    \n",
    "    for table in tables:\n",
    "        rows = []\n",
    "        for row in table.find_all(\"tr\"):\n",
    "            cols = [col.get_text(strip=True) for col in row.find_all([\"td\", \"th\"])]\n",
    "            rows.append(cols)\n",
    "        \n",
    "        # Flatten row values for filtering irrelevant tables\n",
    "        flat_rows = [item for sublist in rows for item in sublist]\n",
    "        if set(flat_rows) == {\"Back\", \"Forward\"}:\n",
    "            continue\n",
    "        \n",
    "        # Convert extracted table to DataFrame\n",
    "        df = pd.DataFrame(rows)\n",
    "        \n",
    "        # Convert to readable text using tabulate\n",
    "        formatted_table = tabulate(df, headers=\"firstrow\", tablefmt=\"grid\")\n",
    "\n",
    "        # Apply reformatting for better retrieval\n",
    "        structured_table = reformat_table(formatted_table)\n",
    "\n",
    "        formatted_tables.append(structured_table)\n",
    "\n",
    "    return \"\\n\\n\".join(formatted_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_list(soup):\n",
    "    # Extract lists properly\n",
    "    lists = []\n",
    "    for ul in soup.find_all(\"ul\"):\n",
    "        items = [li.get_text(strip=True) for li in ul.find_all(\"li\")]\n",
    "        lists.append(items)\n",
    "    return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_content(selectedOptions=None):\n",
    "    \"\"\"\n",
    "    Load and process all .htm files from the base directory.\n",
    "    \"\"\"\n",
    "    htm_files = _list_htm_files()\n",
    "    logging.info(f\"Found {len(htm_files)} .htm files.\")\n",
    "        \n",
    "    if selectedOptions is None:\n",
    "        selectedOptions = [\"text\", \"table\", \"list\"]\n",
    "        \n",
    "    # initialise empty training web documents.\n",
    "    web_documents = []\n",
    "        \n",
    "    page_texts = []\n",
    "\n",
    "    for file_path in htm_files:\n",
    "        try:\n",
    "            with open(file_path, encoding=\"utf-8\") as file:\n",
    "                content = file.read()\n",
    "                    \n",
    "                # ignore the redundant header section from content\n",
    "                content = content[content.find(\"<body>\")+6:content.find(\"</body>\")]\n",
    "                    \n",
    "                soup = BeautifulSoup(content, \"html.parser\")\n",
    "                    \n",
    "                page_links = [a['href'] for a in soup.find_all('a', href=True)]\n",
    "                                                \n",
    "                \n",
    "                clean_text = extract_text(soup)\n",
    "                    \n",
    "                formatted_table = extract_table(soup)\n",
    "                    \n",
    "                lists = extract_list(soup)\n",
    "                        \n",
    "                page_text = f\"\"\"\n",
    "                    \n",
    "                Tables: \n",
    "                ---\n",
    "                {formatted_table}\n",
    "                ---\n",
    "                    \n",
    "                Text:\n",
    "                ---\n",
    "                {clean_text}\n",
    "                ---\n",
    "                    \n",
    "                List:\n",
    "                ---\n",
    "                {lists}\n",
    "                ---\n",
    "                \"\"\"\n",
    " \n",
    "                page_texts.append(page_text)\n",
    "                    \n",
    "                page_data = {\n",
    "                    'text': page_text,\n",
    "                    'link': page_links\n",
    "                }\n",
    "                    \n",
    "                document = Document(\n",
    "                    content = page_data['text']\n",
    "                )\n",
    "\n",
    "                if file_path.endswith(\"GEO_Limits.htm\"):\n",
    "                    print(f\"Content: {document.content}\")\n",
    "                    \n",
    "                web_documents.append(document)\n",
    "                \n",
    "        except UnicodeDecodeError:\n",
    "            logging.error(f\"Could not read the file {file_path}. Check the file encoding.\")\n",
    "\n",
    "    return web_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'replies': [ChatMessage(_role=<ChatRole.ASSISTANT: 'assistant'>, _content=[TextContent(text='Natural Language Processing (NLP) ist ein Teilbereich der K√ºnstlichen Intelligenz, der sich mit der Interaktion zwischen Computern und menschlicher Sprache besch√§ftigt. Ziel ist es, Computern zu erm√∂glichen, Texte und Sprache in einer Weise zu verstehen, zu interpretieren und zu generieren, die f√ºr Menschen nat√ºrlich und sinnvoll ist.')], _name=None, _meta={'model': 'gpt-4o-mini-2024-07-18', 'index': 0, 'finish_reason': 'stop', 'usage': {'completion_tokens': 69, 'prompt_tokens': 33, 'total_tokens': 102, 'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), 'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0)}})]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "\n",
    "messages = [\n",
    "    ChatMessage.from_system(\"Always respond in German even if some input data is in other languages.\"),\n",
    "    ChatMessage.from_user(\"What's Natural Language Processing? Be brief.\"),\n",
    "]\n",
    "\n",
    "chat_generator = OpenAIChatGenerator(model=\"gpt-4o-mini\")\n",
    "chat_generator.run(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\haoch\\miniconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline, Document\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: \n",
      "                    \n",
      "                Tables: \n",
      "                ---\n",
      "                Types: Limits\n",
      "Number of curves: 450\n",
      "Size of curve units: 24\n",
      "Size of curve name: 90\n",
      "Number of pen definitions: 20\n",
      "Curve selection name: 60\n",
      "Curve to lithology name: 50\n",
      "Curve to lithology lithology types: 10\n",
      "Data points per curve: Unlimited\n",
      "Computed curve parameters: 250\n",
      "Size of computed curve parameters name: 12\n",
      "Computed curve expressions: 300\n",
      "Size of computed curve expressions name: 25\n",
      "Size of computed curve parameter description: 150\n",
      "Number of 'curves for surfaces' definitions: 10\n",
      "Number of curve synonym-pairs: 500\n",
      "Number of tracks: 200\n",
      "Number of qualitative tracks: 30\n",
      "Size of track name: 75\n",
      "Number of curve shades per plot: 250\n",
      "Number of zones per curve shade: 50\n",
      "Curve shade name length: 20\n",
      "Number of data files: Unlimited\n",
      "Columns per data file: 450\n",
      "Size of file name (including the path names): 255\n",
      "Size of file ID: 9\n",
      "Number of file ID: 100\n",
      "Auto file load definition name: 40\n",
      "Number of mnemonics per file: 100\n",
      "Number of mnemonics per plot: 600\n",
      "Size of curve mnemonic: 32\n",
      "Size of file mnemonic value: 250\n",
      "Size of plot mnemonic value: 1000\n",
      "Size of mnemonic description: 40\n",
      "Number of free format text blocks per plot: 4500\n",
      "Number of characters per free format text block: 250\n",
      "Number of free format text's related to a symbol: 6\n",
      "Number of free format text tags: 50\n",
      "Free format text tag size: 31\n",
      "Number of track text blocks per plot: 6000\n",
      "Number of characters per track text block: 32000\n",
      "Number of qualitative tracks: 10\n",
      "Number of graduations per qualitative track: 20\n",
      "Qualitative track name length: 32\n",
      "Qualitative track abbreviation length: 8\n",
      "Number of tables: 100\n",
      "Number of rows in 'operations diary' type table: 4320\n",
      "Number of rows in 'normal' and 'operations remarks' type table: 32000\n",
      "Number of fields in a row`: 20\n",
      "Columns per table: 4320\n",
      "Size of table name: 29\n",
      "Size of table ID: 12\n",
      "Size of table column heading: 29\n",
      "Size of postfix: 20\n",
      "Characters for all columns in table: 10000\n",
      "Characters for an individual cell: 1999\n",
      "Number of lithology types: 450\n",
      "Number of lithology sections per plot: 20000\n",
      "%Litho track per plot: 3\n",
      "Number of lithology types per %Litho track: 10\n",
      "Number of modifier types: 450\n",
      "Number of modifiers per plot: 20000\n",
      "Number of symbol types: 1000\n",
      "Number of symbols per plot: 10000\n",
      "Number of lines per plot: 750\n",
      "Number of header & trailers specification files: 100\n",
      "Number of specifications to make a plot header: 50\n",
      "Number of specifications to make a plot trailer: 50\n",
      "Tadpole definitions: 5\n",
      "Tadpole definitions name: 16\n",
      "Minimum dip value: 0\n",
      "Maximum dip value: 90\n",
      "Minimum azimuth value: 0\n",
      "Maximum azimuth value: 360\n",
      "Maximum dip types: 64\n",
      "Maximum length of dip type name: 63\n",
      "Maximum tadpole definition templates: 50\n",
      "Minimum zoom: 0.1\n",
      "Maximum zoom: 10\n",
      "Size of plot description: 29\n",
      "Number of CGM fonts for font mapping: 20\n",
      "Size of CGM font name: 30\n",
      "Scale settings: 23\n",
      "Password length: 16\n",
      "Size of image name: 32\n",
      "User ID's per plot: 64\n",
      "Vendor ID's per plot: 64\n",
      "Maximum layouts per ODF: 19\n",
      "Number of points per polygon in VOB: 20\n",
      "Number of different fonts for VOB: 50\n",
      "Size of text in VOB: 300\n",
      "Memory for all bitmaps and VOBs: 300 KB\n",
      "Maximum imaging tools: 10\n",
      "Maximum pads per tool: 10\n",
      "Maximum sensors per pad: 64\n",
      "Maximum name length: 63\n",
      "Maximum significant decimals: 4\n",
      "Number of query definitions per zone type: 75\n",
      "Correlation items: 50\n",
      "                ---\n",
      "                    \n",
      "                Text:\n",
      "                ---\n",
      "                *Maximize screen to view table of contents*\n",
      "\n",
      "The following restrictions currently apply within each session of GEO, or instance ofODFfile.\n",
      "\n",
      "Once a limit is reached, the system may beep and/or display an error message for that object type.\n",
      "\n",
      "To check whether the following limits have been exceeded, click Statistics from the Help menu.\n",
      "\n",
      "The Statistics dialog box displays the number of modifiers, lithologies, symbols, texts and lines, which are being used in the currently-open ODF.\n",
      "                ---\n",
      "                    \n",
      "                List:\n",
      "                ---\n",
      "                []\n",
      "                ---\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "documents = _load_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a set to track unique documents based on content and meta\n",
    "unique_docs = {}\n",
    "for doc in documents:\n",
    "    doc_key = (doc.content.strip(), tuple(doc.meta.items()))  # Normalize content & meta\n",
    "    if doc_key not in unique_docs:\n",
    "        unique_docs[doc_key] = doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = list(unique_docs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebc3d4e48d148f0ac721eabe999b062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'doc_writer': {'documents_written': 268}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_component(\n",
    "    instance=SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"), name=\"doc_embedder\"\n",
    ")\n",
    "indexing_pipeline.add_component(instance=DocumentWriter(document_store=document_store), name=\"doc_writer\")\n",
    "\n",
    "indexing_pipeline.connect(\"doc_embedder.documents\", \"doc_writer.documents\")\n",
    "\n",
    "indexing_pipeline.run({\"doc_embedder\": {\"documents\": documents}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n"
     ]
    }
   ],
   "source": [
    "print(len(_list_htm_files()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = [\n",
    "    ChatMessage.from_system(\n",
    "        \"\"\"\n",
    "        You are an assistant for helping the users becoming more familiar with using the GEO   \\ \n",
    "        application. \n",
    "            \n",
    "        GEO is an integrated a PC-based integrated well log authoring, analysis and reporting  \\\n",
    "        system which has been developed for petroleum geologists, geoscientists and engineers.\n",
    "            \n",
    "        Answer the user's questions accurately using retrieved information from the Documents  \\\n",
    "        section precisely. The Document section contains the help content written by software  \\ \n",
    "        developers for the GEO application. \n",
    "            \n",
    "        Ensure that the answer is concise and answers the question to the point without the    \\\n",
    "        inclusion of any irrelevant information. Only the answer to the question should be     \\\n",
    "        outputted as the generated response. \n",
    "            \n",
    "        Use the information from the section under the title \"---Feedback---\" as feedback for  \\\n",
    "        making improvements to your answers. Use the feedback as guidelines to determine which \\\n",
    "        area you need to improve your answer after assessing their validity and feasibility.\n",
    "\n",
    "        Context:\n",
    "        {% for document in documents %}\n",
    "            {{ document.content }}\n",
    "        {% endfor %}\n",
    "        Question: {{ question }}\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipe = Pipeline()\n",
    "rag_pipe.add_component(\"embedder\", SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
    "rag_pipe.add_component(\"retriever\", InMemoryEmbeddingRetriever(document_store=document_store))\n",
    "rag_pipe.add_component(\"prompt_builder\", ChatPromptBuilder(template=template))\n",
    "rag_pipe.add_component(\"llm\", OpenAIChatGenerator(model=\"gpt-4o-mini\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x000002A48736CCD0>\n",
       "üöÖ Components\n",
       "  - embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: ChatPromptBuilder\n",
       "  - llm: OpenAIChatGenerator\n",
       "üõ§Ô∏è Connections\n",
       "  - embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.messages (List[ChatMessage])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_pipe.connect(\"embedder.embedding\", \"retriever.query_embedding\")\n",
    "rag_pipe.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "rag_pipe.connect(\"prompt_builder.prompt\", \"llm.messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What's the maximum number of lithology types in a log?\",\n",
    "    \"How many tracks can you define in one ODF?\",\n",
    "    \"How many curve shades can I create?\",\n",
    "    \"How many curves can I load in one go?\",\n",
    "    \"What's the maximum number of headers I can display in my log?\",\n",
    "    \"How many tables can I have in my log?\",\n",
    "    \"What's the maximum number of characters in a single text entry?\",\n",
    "    \"How many symbols can I have in the plot at any one time?\",\n",
    "    \"How many scales can I define?\",\n",
    "    \"What's the maximum number of data files I can load?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b7763ddf30405d92ca400134311b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What's the maximum number of lithology types in a log?\n",
      "Response: The maximum number of lithology types in a log is 450.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf23044958eb45638342f175f3e145e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many tracks can you define in one ODF?\n",
      "Response: The maximum number of tracks per ODF is 200.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1dafbc3186540fd8abc7dba6e0eb39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many curve shades can I create?\n",
      "Response: You can create up to 250 curve shades in one ODF.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce692c2813d4f94ba44ee27997e77be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many curves can I load in one go?\n",
      "Response: You can load an unlimited number of curves in one go in GEO.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ae50f5d61e46b18bf5c5d8e29745f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What's the maximum number of headers I can display in my log?\n",
      "Response: The document does not specify the maximum number of headers that can be displayed in your log. Please refer to the software‚Äôs limits on header quantities in the relevant documentation for that information.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca6a2d4b255432a9cf16ab5bd552fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many tables can I have in my log?\n",
      "Response: You can have a maximum of 100 tables in one ODF file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a443608bd6a84875a8184921f7ad7ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What's the maximum number of characters in a single text entry?\n",
      "Response: The maximum number of characters in a single text entry is determined by the size of the text box, which can be edited as needed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3568025b0d4eebba1872416658852f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many symbols can I have in the plot at any one time?\n",
      "Response: You can have up to 250 shadings applied in one ODF.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae333382d5840d19d2cce114a4ec803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many scales can I define?\n",
      "Response: You can define multiple scales for a curve in a plot, allowing for scale changes at different points in the plot.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ad8314cea645b2a93cb6693738e677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What's the maximum number of data files I can load?\n",
      "Response: The maximum number of data files you can load in GEO is unlimited.\n"
     ]
    }
   ],
   "source": [
    "predicted_responses = []\n",
    "for query in questions:\n",
    "    response = rag_pipe.run({\"embedder\": {\"text\": query}, \"prompt_builder\": {\"question\": query}})\n",
    "    print(f\"Question: {query}\")\n",
    "    predicted_responses.append(response['llm']['replies'][0]._content[0].text)\n",
    "    print(f\"Response: {response['llm']['replies'][0]._content[0].text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample response: [450, 200, 250, 450, 50, 100, '250 / 32000 (varies per text type)', 10000, 23, 'unlimited']\n"
     ]
    }
   ],
   "source": [
    "sample_responses = [\n",
    "    450, \n",
    "    200, \n",
    "    250, \n",
    "    450, \n",
    "    50, \n",
    "    100, \n",
    "    \"250 / 32000 (varies per text type)\", \n",
    "    10000, \n",
    "    23, \n",
    "    \"unlimited\"\n",
    "]\n",
    "\n",
    "print(f\"sample response: {sample_responses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted response: ['The maximum number of lithology types in a log is 450.', 'The maximum number of tracks per ODF is 200.', 'You can create up to 250 curve shades in one ODF.', 'You can load an unlimited number of curves in one go in GEO.', 'The document does not specify the maximum number of headers that can be displayed in your log. Please refer to the software‚Äôs limits on header quantities in the relevant documentation for that information.', 'You can have a maximum of 100 tables in one ODF file.', 'The maximum number of characters in a single text entry is determined by the size of the text box, which can be edited as needed.', 'You can have up to 250 shadings applied in one ODF.', 'You can define multiple scales for a curve in a plot, allowing for scale changes at different points in the plot.', 'The maximum number of data files you can load in GEO is unlimited.']\n"
     ]
    }
   ],
   "source": [
    "print(f\"predicted response: {predicted_responses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    \"Expected Response\": sample_responses,\n",
    "    \"Predicted Response\": predicted_responses\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ace_tools_open as tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Question Results DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table id=\"itables_3903a21f_45c2_4217_b978_6dab9fe4bd47\" class=\"display nowrap\" data-quarto-disable-processing=\"true\" style=\"table-layout:auto;width:auto;margin:auto;caption-side:bottom\">\n",
       "<thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      \n",
       "      <th>Expected Response</th>\n",
       "      <th>Predicted Response</th>\n",
       "    </tr>\n",
       "  </thead><tbody><tr>\n",
       "<td style=\"vertical-align:middle; text-align:left\">\n",
       "<a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
       "    <g style=\"fill:#d9d7fc\">\n",
       "        <path d=\"M100,400H500V357H100Z\" />\n",
       "        <path d=\"M100,300H400V257H100Z\" />\n",
       "        <path d=\"M0,200H400V157H0Z\" />\n",
       "        <path d=\"M100,100H500V57H100Z\" />\n",
       "        <path d=\"M100,350H500V307H100Z\" />\n",
       "        <path d=\"M100,250H400V207H100Z\" />\n",
       "        <path d=\"M0,150H400V107H0Z\" />\n",
       "        <path d=\"M100,50H500V7H100Z\" />\n",
       "    </g>\n",
       "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
       "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"0;0;400\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;300;0\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;400\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
       "            <g transform=\"translate(45 50) rotate(-45)\">\n",
       "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
       "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(450 152)\">\n",
       "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
       "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(50 352)\">\n",
       "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
       "                <polygon points=\"-35,10 0,45 35,10\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(75 250)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(425 250) rotate(180)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "        </g>\n",
       "    </g>\n",
       "</svg>\n",
       "</a>\n",
       "Loading ITables v2.2.4 from the internet...\n",
       "(need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
       "</tr></tbody>\n",
       "</table>\n",
       "<link href=\"https://www.unpkg.com/dt_for_itables@2.0.13/dt_bundle.css\" rel=\"stylesheet\">\n",
       "<script type=\"module\">\n",
       "    import {DataTable, jQuery as $} from 'https://www.unpkg.com/dt_for_itables@2.0.13/dt_bundle.js';\n",
       "\n",
       "    document.querySelectorAll(\"#itables_3903a21f_45c2_4217_b978_6dab9fe4bd47:not(.dataTable)\").forEach(table => {\n",
       "        if (!(table instanceof HTMLTableElement))\n",
       "            return;\n",
       "\n",
       "        // Define the table data\n",
       "        const data = [[\"450\", \"The maximum number of lithology types in a log is 450.\"], [\"200\", \"The maximum number of tracks per ODF is 200.\"], [\"250\", \"You can create up to 250 curve shades in one ODF.\"], [\"450\", \"You can load an unlimited number of curves in one go in GEO.\"], [\"50\", \"The document does not specify the maximum number of headers that can be displayed in your log. Please refer to the software\\u2019s limits on header quantities in the relevant documentation for that information.\"], [\"100\", \"You can have a maximum of 100 tables in one ODF file.\"], [\"250 / 32000 (varies per text type)\", \"The maximum number of characters in a single text entry is determined by the size of the text box, which can be edited as needed.\"], [\"10000\", \"You can have up to 250 shadings applied in one ODF.\"], [\"23\", \"You can define multiple scales for a curve in a plot, allowing for scale changes at different points in the plot.\"], [\"unlimited\", \"The maximum number of data files you can load in GEO is unlimited.\"]];\n",
       "\n",
       "        // Define the dt_args\n",
       "        let dt_args = {\"layout\": {\"topStart\": null, \"topEnd\": null, \"bottomStart\": null, \"bottomEnd\": null}, \"order\": [], \"warn_on_selected_rows_not_rendered\": true};\n",
       "        dt_args[\"data\"] = data;\n",
       "\n",
       "        \n",
       "        new DataTable(table, dt_args);\n",
       "    });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tools.display_dataframe_to_user(name=\"Sample Question Results DataFrame\", dataframe=comparison_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
