{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os # for getting API token from env variable OPENAI_API_KEY\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "client = OpenAI(api_key=openai.api_key)\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Well log authoring, analysis, and reporting system\",\n",
    "  instructions=\"Use your knowledge about GEO suite to provide an efficient guide to help the users with using this application.\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"file_search\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"Data\"\n",
    "\n",
    "def _list_htm_files(file_format):\n",
    "    \"\"\"\n",
    "    Recursively finds all .htm files in the base directory and its subdirectories.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of file paths relative to the base directory.\n",
    "    \"\"\"\n",
    "    htm_files = []\n",
    "    for root, _, files in os.walk(base_directory):\n",
    "        for file in files:\n",
    "            if file.endswith(file_format):\n",
    "                relative_path = os.path.relpath(os.path.join(root, file), start=base_directory)\n",
    "                htm_files.append(base_directory + \"/\" + relative_path)\n",
    "    return htm_files\n",
    "\n",
    "htm_filepaths = _list_htm_files(\".html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_htm_to_html():\n",
    "    \"\"\"\n",
    "    Converts all .htm files to .html format in the base directory and its subdirectories,\n",
    "    skipping files that are already in .html format.\n",
    "    \"\"\"\n",
    "    htm_files = _list_htm_files('.htm')\n",
    "    for file in htm_files:\n",
    "        html_file = file.replace('.htm', '.html')\n",
    "        if not os.path.exists(html_file):  # Check if the .html file already exists\n",
    "            # Read the content of the .htm file and write it to the new .html file\n",
    "            with open(file, 'r', encoding='utf-8') as htm_file:\n",
    "                content = htm_file.read()\n",
    "            with open(html_file, 'w', encoding='utf-8') as html_file:\n",
    "                html_file.write(content)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "convert_htm_to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=120, failed=149, in_progress=0, total=269)\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.beta.vector_stores.create(name=\"GEO Help Guide\")\n",
    "\n",
    "file_streams = [open(path, \"rb\") for path in htm_filepaths]\n",
    "\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolResourcesFileSearch(vector_store_ids=['vs_shgj9Uw0jthoFJk63ABT20Vv'])\n"
     ]
    }
   ],
   "source": [
    "# Upload the user provided file to OpenAI\n",
    "message_file = client.files.create(\n",
    "  file=open(\"Data/Introduction/Geo_Limits.html\", \"rb\"), purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "# Create a thread and attach the file to the message\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Could you summarise this file contents?\",\n",
    "      # Attach the new file to the message.\n",
    "      \"attachments\": [\n",
    "        { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "# The thread now has a vector store with that file in its tool resources.\n",
    "print(thread.tool_resources.file_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > Could you let me know the limits to the number of curves that can be plotted in the document? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler, OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_message_done(self, message) -> None:\n",
    "        # print a citation to the file searched\n",
    "        message_content = message.content[0].text\n",
    "        annotations = message_content.annotations\n",
    "        citations = []\n",
    "        for index, annotation in enumerate(annotations):\n",
    "            message_content.value = message_content.value.replace(\n",
    "                annotation.text, f\"[{index}]\"\n",
    "            )\n",
    "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "                cited_file = client.files.retrieve(file_citation.file_id)\n",
    "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "        print(message_content.value)\n",
    "        print(\"\\n\".join(citations))\n",
    "\n",
    "# Then, we use the stream SDK helper\n",
    "# with the EventHandler class to create the Run\n",
    "# and stream the response.\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"What are the limits to the number of curves that can be plotted?\",\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
